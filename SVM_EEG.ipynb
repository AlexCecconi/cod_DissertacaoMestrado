{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilitarios\n",
    "from statsmodels.stats.descriptivestats import Description\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mne.externals.pymatreader import read_mat\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "#Rede Neural\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dropout, BatchNormalization \n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "os.environ['TENSORBOARD_BINARY'] = '/path/to/envs/my_env/bin/tensorboard'\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject1_01 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject1_mat\\train_subject1_raw01.mat')\n",
    "subject1_02 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject1_mat\\train_subject1_raw02.mat')\n",
    "subject1_03 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject1_mat\\train_subject1_raw03.mat')\n",
    "\n",
    "subject2_01 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject2_mat\\train_subject2_raw01.mat')\n",
    "subject2_02 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject2_mat\\train_subject2_raw02.mat')\n",
    "subject2_03 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject2_mat\\train_subject2_raw03.mat')\n",
    "\n",
    "subject3_01 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject3_mat\\train_subject3_raw01.mat')\n",
    "subject3_02 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject3_mat\\train_subject3_raw02.mat')\n",
    "subject3_03 = read_mat(r'C:\\Users\\Alex\\Desktop\\EEG\\subject3_mat\\train_subject3_raw03.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe63047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject1_01['nfo']              #items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_X = np.concatenate( (subject1_01['X'], subject1_02['X'], subject1_03['X'], subject2_01['X'], subject2_02['X'], subject2_03['X'], subject3_01['X'], subject3_02['X'], subject3_03['X'] ), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123eb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_Y = np.concatenate( (subject1_01['Y'], subject1_02['Y'], subject1_03['Y'], subject2_01['Y'], subject2_02['Y'], subject2_03['Y'], subject3_01['Y'], subject3_02['Y'], subject3_03['Y'] ), axis = 0)\n",
    "subject_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processamento dos dados\n",
    "ICA = FastICA()\n",
    "\n",
    "subject_X = ICA.fit_transform(subject_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.take( subject_Y , np.arange(0, len( subject_X ), 512) , axis=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(  np.split( np.transpose( subject_X ), 2141, axis = 1 ))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame( Description( X[0].flatten() ).summary() ).T # Vai duplica a primeira linha\n",
    "\n",
    "for i in range(  X.shape[0] ):\n",
    "    r = pd.DataFrame( Description( X[i].flatten() ).summary() ).T\n",
    "    t = t.append(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704439fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.empty( 16384 )\n",
    "for j in range(  X.shape[0] ):\n",
    "    v = X[j].flatten() \n",
    "    z = np.vstack((z,v))\n",
    "z = np.delete(arr = z, obj = 0, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db102224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = np.delete(arr = z, obj = 0, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA( n_components = 8) # mle - 12\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bca462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b459613",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(r'C:\\Users\\Alex\\Desktop\\testao.csv', decimal = ',', sep = '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fdd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_excel(r'C:\\Users\\Alex\\Desktop\\x_eeg_svm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d365afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( z, Y, test_size=0.20, random_state=42, stratify = Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccc789",
   "metadata": {},
   "source": [
    "NUM_CLASSES = 3\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "#y_val = le.fit_transform(y_val)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "#Faz One-Hot Encoding\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "#y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94169c08",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters2 = [{'SVC__kernel': ['rbf'], 'SVC__gamma': [1000, 100, 10, 1,0.1,0.01,0.001, 'scale'],  'SVC__C': [0.01,0.001, 0.1,1, 10, 100, 1000], 'SVC__decision_function_shape' : ['ovo', 'ovr'], 'SVC__class_weight':['balanced', None]},\n",
    "                    {'SVC__kernel': ['poly'], 'SVC__gamma': [1000, 100, 10, 1,0.1,0.01,0.001, 'scale'], 'SVC__C': [0.01,0.001, 0.1,1, 10, 100, 1000], 'SVC__decision_function_shape' : ['ovo', 'ovr'], 'SVC__class_weight':['balanced', None], 'SVC__degree': [2,3,4]},\n",
    "                    {'SVC__kernel': ['sigmoid'], 'SVC__gamma': [1000, 100, 10, 1,0.1,0.01,0.001, 'scale'], 'SVC__C': [0.01,0.001, 0.1,1, 10, 100, 1000], 'SVC__decision_function_shape' : ['ovo', 'ovr'], 'SVC__class_weight':['balanced', None]},\n",
    "                    {'SVC__kernel': ['linear'], 'SVC__C': [0.01,0.001, 0.1,1, 10, 100, 1000], 'SVC__decision_function_shape' : ['ovo', 'ovr'], 'SVC__class_weight':['balanced', None]}\n",
    "                    ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_parameters2 = [{'SVC__kernel': ['rbf'], 'SVC__gamma': [1000, 100, 10, 1,0.1,0.01,0.001, 'scale'],  'SVC__C': [0.01,0.001, 0.1,1, 10, 100, 1000], 'SVC__decision_function_shape' : ['ovo', 'ovr'], 'SVC__class_weight':['balanced', None]}] \n",
    "tuned_parameters2 = [{'SVC__kernel': ['rbf'], 'SVC__gamma': [ 'scale'],}]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    return cm[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c249bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scoring = ['accuracy', 'precision'] #str\n",
    "#scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#           'precision': make_scorer(precision_score, average = 'weighted'),\n",
    "#           'recall': make_scorer(recall_score, average = 'weighted'),\n",
    "#           'f1_macro': make_scorer(f1_score, average = 'macro'),\n",
    "#            'f1_weighted': make_scorer(f1_score, average = 'weighted')} # Se average = None, é calculado a metrica por rotulo\n",
    "scoring = {'score': confusion_matrix_scorer } \n",
    "#scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#           'precision': make_scorer(precision_score, average = None)}\n",
    "\n",
    "\n",
    "#pipe2 = Pipeline(steps=[ ('StandardScaler', StandardScaler()), ('PCA', PCA( n_components = 12 )), ('SVC', SVC()) ])\n",
    "#pipe2 = Pipeline(steps=[ ('StandardScaler', StandardScaler()), ('TSNE', TSNE()), ('SVC', SVC()) ])\n",
    "pipe2 = Pipeline(steps=[ ('StandardScaler', StandardScaler()), ('SVC', SVC()) ])\n",
    "\n",
    "clf2 = GridSearchCV( pipe2, tuned_parameters2, scoring=scoring ,verbose=100, cv = 1, refit = make_scorer(accuracy_score) )  #, n_jobs = -1 #, refit='AUC'\n",
    "\n",
    "clf2.fit( x_train  , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ba430",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46191da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c94af",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
